{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKpuubCfX9SIvYrXe5Nlqg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivekkishore/Pythonbasics/blob/main/meetingclassifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Preprocessing"
      ],
      "metadata": {
        "id": "9rxJhjkTQHOF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "eswrQj1wP0V_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "131fa87f-49c8-4c70-dc57-04fe9833ab92"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    New Digital Content Form discussion, In the ca...\n",
              "1    migration from Shibboleth to SAML, We will dis...\n",
              "2    GLR Discussion, Could we meet for 30 minutes t...\n",
              "3    Discussion on SSO progress, Scheduling this ca...\n",
              "4    Learn to balance your ideas using value with F...\n",
              "Name: meeting details, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import seaborn\n",
        "# import sklearn\n",
        "# import matplotlib.pyplot as plt\n",
        "# %matplotlib inline\n",
        "# from pylab import rcParams\n",
        "# rcParams['figure.figsize'] = 10, 8\n",
        "# from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
        "# from sklearn.pipeline import Pipeline\n",
        "# from sklearn import preprocessing\n",
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "# from sklearn import tree\n",
        "# from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "# from sklearn.metrics import classification_report,confusion_matrix, roc_auc_score, accuracy_score\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer,TfidfTransformer,CountVectorizer\n",
        "# df=pd.read_excel('meetingtype.xlsx')\n",
        "# df.head()\n",
        "# X=df['meeting details']\n",
        "# Y=df['meeting type']\n",
        "X.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import spacy\n",
        "# import string\n",
        "# import gensim\n",
        "# import operator\n",
        "# import re\n",
        "# from spacy.lang.en.stop_words import STOP_WORDS\n",
        "# spacy_nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def spacy_tokenizer(sentence):\n",
        "\n",
        "    punctuations = string.punctuation\n",
        "    stop_words = STOP_WORDS\n",
        "    #remove distracting single quotes\n",
        "    sentence = re.sub('\\'','',sentence)\n",
        "\n",
        "    #remove digits and words containing digits\n",
        "    sentence = re.sub('\\w*\\d\\w*','',sentence)\n",
        "\n",
        "    #replace extra spaces with single space\n",
        "    sentence = re.sub(' +',' ',sentence)\n",
        "\n",
        "    #remove non-breaking new line characters\n",
        "    sentence = re.sub(r'\\n',' ',sentence)\n",
        "\n",
        "    #creating token object\n",
        "    tokens = spacy_nlp(sentence)\n",
        "\n",
        "    #lower, strip and lemmatize\n",
        "    tokens = [word.lemma_.lower().strip() for word in tokens]\n",
        "\n",
        "    #remove stopwords, and exclude words less than 2 characters\n",
        "    tokens = [word for word in tokens if word not in stop_words and word not in punctuations and len(word) > 2]\n",
        "\n",
        "    return tokens\n"
      ],
      "metadata": {
        "id": "26YxpAL0hqUu"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent1='Test call, scheduling call to discuss test results'\n",
        "result=spacy_tokenizer(sent1)\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMc5HoSwi2ac",
        "outputId": "7f4b46dd-3564-417b-a03c-3733df5e1237"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['test', 'scheduling', 'discuss', 'test', 'result']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_clf = Pipeline([('vect', CountVectorizer()), ('tfidf', TfidfTransformer()), ('clf', MultinomialNB())])\n",
        "# text_clf = text_clf.fit(X_train, y_train)\n",
        "\n",
        "n_iter_search = 5\n",
        "parameters = {'vect__ngram_range': [(1, 1), (1, 2)], 'tfidf__use_idf': (True, False), 'clf__alpha': (1e-2, 1e-3)}\n",
        "gs_clf = RandomizedSearchCV(text_clf, parameters, n_iter = n_iter_search)\n",
        "\n",
        "# gs_clf = gs_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "ciFfrXRQi2dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L0tiF080hqXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_EZ0ic55hqbN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}